{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30749,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n# from plotly.subplots import make_subplots\n# import plotly.graph_objects as go\n# import plotly.express as px\nfrom scipy.integrate import solve_ivp \nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom mpl_toolkits import mplot3d\nimport string\nimport networkx as nx","metadata":{"execution":{"iopub.status.busy":"2024-08-20T12:34:32.395664Z","iopub.execute_input":"2024-08-20T12:34:32.396098Z","iopub.status.idle":"2024-08-20T12:34:35.477809Z","shell.execute_reply.started":"2024-08-20T12:34:32.396012Z","shell.execute_reply":"2024-08-20T12:34:35.476702Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Simul params","metadata":{"papermill":{"duration":0.007373,"end_time":"2023-08-13T18:34:03.046357","exception":false,"start_time":"2023-08-13T18:34:03.038984","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Number of individuals in the community\nN = 10000\n\n# Number of communities and edges added per epoch\nM = 100\n\n# Start and End epochs\nt0, tf = 0, 3000\n\n# Number of timesteps\nNt = 3000\n\n# Time series\nt = np.linspace(t0, tf, Nt + 1)\n\n# Fraction of patches where we will apply the test kits\np = 0.4\n\n# Num of patches where we will apply the test kits\nl1 = int(p*M)            # For p fraction\nl2 = M-l1                # For the reverse case\n\n# Differential equation params\nsigma = 0.1\na0 = 0.01\na1 = 0.0001\ngamma = 0.07\nzeta = 0.02\nchi = 0.1\n\n# Setup for the beta slider\nbeta_min = 0\nbeta_max = 0.06\n\nbeta_steps = M - 1\n\n# Coupling strength steps\nepsilon_steps = M\n\n# The randomisation for exposed population will be upto max_exposed\nmax_exposed = 300\n\n# Generating all the lists\nepsilon_list = np.logspace(-5, 1, epsilon_steps, base=10)","metadata":{"papermill":{"duration":0.020933,"end_time":"2023-08-13T18:34:03.074584","exception":false,"start_time":"2023-08-13T18:34:03.053651","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Making a complete graph with 4 Nodes\nadj_mat = np.full((M, M), 1, dtype=\"int\").reshape(M, M)\n# graph = nx.erdos_renyi_graph(M, 0.3, seed=None, directed=False)\n# adj_mat = nx.to_numpy_array(graph).reshape(M, M)\n\n# Making the degree list for each node (di = M-1 here)\ndegree_list = np.sum(adj_mat, axis=0).reshape(M, 1)\navg_degree=np.mean(degree_list)\n\n# Dividing the adjacency matrix by rowsum\nrow_sums= np.sum(adj_mat, axis=1)\nadj_mat_normalised = (adj_mat/row_sums[:,np.newaxis]).reshape(M, M)","metadata":{"papermill":{"duration":0.027959,"end_time":"2023-08-13T18:34:03.110220","exception":false,"start_time":"2023-08-13T18:34:03.082261","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_degree_counts(n : int, adj_mat):\n    freq_map = np.zeros(n) # degree -> count\n    for i in range(n):\n        num_neighbours = int(np.sum(adj_mat[i]))\n        freq_map[num_neighbours] += 1\n    return np.array(freq_map)","metadata":{"papermill":{"duration":0.017612,"end_time":"2023-08-13T18:34:03.135457","exception":false,"start_time":"2023-08-13T18:34:03.117845","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Returns a probabiltity distribution\n# that is based on degree, pi = di/total(di) \ndef degree_centrality(adj_mat, patches_to_apply):\n    # Get degree_list\n    degree_list = np.sum(adj_mat, axis=0, dtype=\"float\")\n    # Replace with zero in the range [patches_to_apply, len(adj_list))\n    np.put(degree_list, np.arange(patches_to_apply, M), 0)\n\n    return degree_list / np.sum(degree_list, dtype=\"float\")","metadata":{"papermill":{"duration":0.01897,"end_time":"2023-08-13T18:34:03.161770","exception":false,"start_time":"2023-08-13T18:34:03.142800","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Returns a uniform probability distribution\ndef const_prob(adj_mat, patches_to_apply):\n    m = int(len(adj_mat)) # Number of communities\n\n    # each node as probability as 1/patches_to_apply\n    retval = np.full(m, 1, dtype=\"float\") / float(patches_to_apply)\n\n    # Replace with zero in the range [patches_to_apply, len(adj_list))\n    np.put(retval, np.arange(patches_to_apply, M), 0)\n\n    return retval","metadata":{"papermill":{"duration":0.018714,"end_time":"2023-08-13T18:34:03.188049","exception":false,"start_time":"2023-08-13T18:34:03.169335","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Returns node wise distribution strategy for test kits\ndef g_val(a1, K, prob_distri_test_kit):\n    return a1 * K * prob_distri_test_kit","metadata":{"papermill":{"duration":0.01673,"end_time":"2023-08-13T18:34:03.212217","exception":false,"start_time":"2023-08-13T18:34:03.195487","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def migration_term(adj_mat, adj_mat_normalised, compartment):\n    # Getting the Amn x Sm term\n    retval = np.dot(adj_mat_normalised, compartment).reshape(int(len(compartment)), 1)\n    \n    # Returning the migration amount\n    return (retval - compartment)","metadata":{"papermill":{"duration":0.017615,"end_time":"2023-08-13T18:34:03.237124","exception":false,"start_time":"2023-08-13T18:34:03.219509","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ODE_multi_node_with_testkit(t, X_flat, beta, adj_mat, adj_mat_normalised, degree_list, shape_X, epsilon, num_patches, l, gamma, sigma, zeta, chi, a0, a1):\n    # Unraveling the X_flat vector\n    X = X_flat.reshape(shape_X) \n    S, E, I, H, R, K = X\n    \n    # Reshaping into patchesx1 matrix from rank-1 array\n    S = S.reshape(num_patches, 1)\n    E = E.reshape(num_patches, 1)\n    I = I.reshape(num_patches, 1)\n    H = H.reshape(num_patches, 1)\n    R = R.reshape(num_patches, 1)\n    \n    # Warning : K is a number NOT a list\n    # So, we will turn it into a \"fake\" list by repeating it num_patches times\n    K = K.reshape(num_patches, 1)\n    \n    # We are using degree centrality based test kit distribution\n    g = g_val(a1, K[0], const_prob(adj_mat, l).reshape(num_patches, 1))\n\n    # Reshaping into num_patches x 1 matrix\n    g = g.reshape(num_patches, 1)\n    \n    # Obtaining the total population of each patch\n    tot_pop = S + E + I + H + R\n    \n    # Hospitalization param\n    alpha = a0 + g\n    \n    S_migration = ((epsilon) * migration_term(adj_mat, adj_mat_normalised, S)).reshape(num_patches, 1)\n    E_migration = ((epsilon) * migration_term(adj_mat, adj_mat_normalised, E)).reshape(num_patches, 1)\n    I_migration = ((epsilon) * migration_term(adj_mat, adj_mat_normalised, I)).reshape(num_patches, 1)\n    R_migration = ((epsilon) * migration_term(adj_mat, adj_mat_normalised, R)).reshape(num_patches, 1)\n    \n    # Find the derivatives list, broadcasting coming in clutch now\n    dSdt = (np.divide(-(beta * S * I), tot_pop)) +  S_migration\n    dEdt = (np.divide((beta * S * I), tot_pop)) - (sigma * E) + E_migration\n    dIdt = (sigma * E) -  (alpha * I) + I_migration\n    dHdt = (alpha * I) - (gamma * H)\n    dRdt = (gamma * H) + R_migration\n    dKdt = (zeta * np.full(num_patches, np.sum(I)).reshape(num_patches, 1)) - (chi * K)\n    \n    # Reshape the derivatives list for good measure\n    dSdt = dSdt.reshape(num_patches, 1)\n    dEdt = dEdt.reshape(num_patches, 1)\n    dIdt = dIdt.reshape(num_patches, 1)\n    dHdt = dHdt.reshape(num_patches, 1)\n    dRdt = dRdt.reshape(num_patches, 1)\n    dKdt = dKdt.reshape(num_patches, 1)\n        \n    derivs =  np.array([dSdt, dEdt, dIdt, dHdt, dRdt, dKdt])\n    \n    return derivs.ravel()\n\ndef ODE_multi_node_without_testkit(t, X_flat, beta, adj_mat, adj_mat_normalised, degree_list, shape_X, epsilon, num_patches, l, gamma, sigma, zeta, chi, a0, a1):\n    return ODE_multi_node_with_testkit(t, X_flat, beta, adj_mat, adj_mat_normalised, degree_list, shape_X, epsilon, num_patches, l, gamma, sigma, zeta, chi, a0, 0)","metadata":{"papermill":{"duration":0.031158,"end_time":"2023-08-13T18:34:03.275630","exception":false,"start_time":"2023-08-13T18:34:03.244472","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-08-20T12:32:43.010871Z","iopub.execute_input":"2024-08-20T12:32:43.055202Z","iopub.status.idle":"2024-08-20T12:32:43.123474Z"},"trusted":true},"execution_count":2,"outputs":[{"ename":"ERROR","evalue":"Error in parse(text = x, srcfile = src): <text>:1:5: unexpected symbol\n1: def ODE_multi_node_with_testkit\n        ^\n","traceback":["Error in parse(text = x, srcfile = src): <text>:1:5: unexpected symbol\n1: def ODE_multi_node_with_testkit\n        ^\nTraceback:\n"],"output_type":"error"}]},{"cell_type":"code","source":"def solver(adj_mat, adj_mat_normalised, degree_list, M, beta, ODE_func, E0, epsilon, num_patches, l):\n    # Initial conditions for given beta\n    I0, H0, R0, K0 = np.zeros(M), np.zeros(M), np.zeros(M), np.zeros(M)\n\n    # Mandatory reshaping, for safety\n    E0 = E0.reshape(M, 1)\n    I0 = I0.reshape(M, 1)\n    H0 = H0.reshape(M, 1)\n    R0 = R0.reshape(M, 1)\n    K0 = K0.reshape(M, 1)\n    \n    # Getting the susceptibles\n    # [TBX : This makes N*M susceptibles by broadcasting]\n    Total_population = np.full(M, N).reshape(M, 1)\n    S0 = Total_population - E0 - I0 - H0 - R0\n    S0 = S0.reshape(M, 1)\n\n    # Making the state vector\n    X0 = np.array([S0, E0, I0, H0, R0, K0])\n\n    # Ravel the X vector temporarily\n    shape_X = X0.shape\n    X_flat = X0.ravel()\n\n    # Solving the initial value problem\n    solved_ivp = solve_ivp(ODE_func, (t0, tf), X_flat, args=(beta, adj_mat, adj_mat_normalised, degree_list, shape_X, epsilon, num_patches, l, gamma, sigma, zeta, chi, a0, a1), t_eval=t)\n\n    # Returning the raw solved ivp data for plotting\n    # solved_ivp.y.reshape(6, M, Nt+1)\n    return solved_ivp","metadata":{"papermill":{"duration":0.022465,"end_time":"2023-08-13T18:34:03.305478","exception":false,"start_time":"2023-08-13T18:34:03.283013","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Functions for reduced equations","metadata":{"papermill":{"duration":0.007145,"end_time":"2023-08-13T18:34:03.320064","exception":false,"start_time":"2023-08-13T18:34:03.312919","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def func(mig_array, H, K, alpha, beta, gamma, sigma, zeta, chi):\n    S,E,I,R= mig_array\n    N_mig_arr= np.sum(mig_array) + H\n\n    mig_array_dot= np.array([\n        -beta*S*I / N_mig_arr,\n        beta*S*I / N_mig_arr - sigma*E, \n        sigma*E - alpha*I, \n        gamma*H\n    ])\n    \n    return mig_array_dot, alpha*I-gamma*H","metadata":{"papermill":{"duration":0.018486,"end_time":"2023-08-13T18:34:03.345984","exception":false,"start_time":"2023-08-13T18:34:03.327498","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ODE_for_reduced_eqns(t, X_flat, l1,l2, epsilon, beta, gamma, sigma, zeta, chi, a0, a1):\n    mig_array = X_flat[0:8]\n    H1= X_flat[8]\n    H2=X_flat[9]\n    K= X_flat[10]\n    \n    # Getting the 2*4 migration variables\n    mig_array = mig_array.reshape(2,4)\n    \n    # Getting the 2 communities\n    C1 = mig_array[0]\n    C2 = mig_array[1]\n    \n    # Getting alpha for C1 and C2\n    alpha_C1 = a0 + a1*K/l1\n    alpha_C2 = a0\n    \n    # Getting derivatives\n    C1_dot,H1_dot = func(C1, H1, K, alpha_C1, beta, gamma, sigma, zeta, chi) \n    C2_dot,H2_dot = func(C2, H2, K, alpha_C2, beta, gamma, sigma, zeta, chi)\n    \n    C1_dot = C1_dot + (l2*epsilon/(avg_degree))*(C2-C1)\n    C2_dot = C2_dot + (l1*epsilon/(avg_degree))*(C1-C2)\n    \n    K_dot = zeta*(l1*C1[2]+l2*C2[2]) - chi*K\n    \n    X_dot = np.concatenate((C1_dot,C2_dot,H1_dot,H2_dot,K_dot), axis=None)\n    \n    return X_dot","metadata":{"papermill":{"duration":0.022684,"end_time":"2023-08-13T18:34:03.377432","exception":false,"start_time":"2023-08-13T18:34:03.354748","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X and Y with testkits\nx_with_testkits1 = np.array([])\ny_with_testkits1 = np.array([])\ny_with_testkits1_mean = np.array([])\ny_with_testkits1_max = np.array([])\ny_with_testkits1_min = np.array([])\n\n# X and Y without testkits\nx_without_testkits1 = np.array([])\ny_without_testkits1 = np.array([])\ny_without_testkits1_mean = np.array([])\ny_without_testkits1_max = np.array([])\ny_without_testkits1_min = np.array([])\n    \n# Arrays for reduced equation solver\nx_with_testkitsR1 = np.array([])\nx_without_testkitsR1 = np.array([])\n\nfor epsilon_value in epsilon_list:\n    # initial conditions\n    custom_E0 = np.random.randint(1, max_exposed, size=(M,1))\n#-------------------Reduced Model-----------------------\n    E1,E2= custom_E0[0][0],custom_E0[l1][0]\n    # Initial conditions for given epsilon\n    X0= np.array([N-E1,E1,0,0,N-E2,E2,0,0,0,0,0])\n\n    X_flat = X0.ravel()\n\n    # Solving the initial value problem\n    solved_ivp = solve_ivp(ODE_for_reduced_eqns, (t0, tf), X_flat, args=(l1, M-l1, epsilon_value,  0.03, gamma, sigma, zeta, chi, a0, a1))\n\n    # Obtaining the Infection values for both communities\n    I_1 = solved_ivp.y[2]\n    I_2 = solved_ivp.y[6]\n\n    # Getting the I_max values from I_vals\n    I_max_1 = np.max(I_1)\n    I_max_2 = np.max(I_2)\n    \n    x_with_testkitsR1 = np.append(x_with_testkitsR1, I_max_1/N)\n    x_without_testkitsR1 = np.append(x_without_testkitsR1, I_max_2/N)\n#--------------------------------------------------------\n\n    # Solving the IVP using our solver function\n    solved_ivp = solver(adj_mat, adj_mat_normalised, degree_list, M, 0.03, ODE_multi_node_with_testkit, custom_E0, epsilon_value, M, l1)\n\n    # Obtaining the shape we need to realize the y values\n    reshape_vals = (6, M, solved_ivp.y.shape[1])\n    \n    # Getting the y value reshaped\n    jffy = solved_ivp.y.reshape(reshape_vals)[2]\n\n    # Obtaining the Infection values for each communities\n    I_vals = (solved_ivp.y.reshape(6, M, reshape_vals[2])[2]).reshape(M, reshape_vals[2])\n\n    # Getting the I_max values from I_vals\n    I_max = np.max(I_vals, axis=1).reshape(M, 1)\n    \n    # Colour list for testkit and testkit-free communities\n    color_list = [\"#F08080\", \"#80F080\", \"#8080F0\"]\n    \n    # x1, y1 for the \"with testkit nodes\"\n    x1 = np.full(M, epsilon_value)[:l1]\n    y1 = I_max.T[0][:l1] / N\n    marker_color_with_testkits = color_list[0]\n    \n    y_with_testkits1 = np.append(y_with_testkits1, y1)\n    x_with_testkits1 = np.append(x_with_testkits1, x1)\n    y_with_testkits1_mean = np.append(y_with_testkits1_mean, [np.sum(y1) / l1])\n    y_with_testkits1_max = np.append(y_with_testkits1_max, [np.max(y1)])\n    y_with_testkits1_min = np.append(y_with_testkits1_min, [np.min(y1)])\n    \n    # x2, y2 for the \"without testkit nodes\"\n    x2 = np.full(M, epsilon_value)[l1:-1]\n    y2 = I_max.T[0][l1:-1] / N\n    marker_color_without_testkits = color_list[1]\n    \n    y_without_testkits1 = np.append(y_without_testkits1, y2)\n    x_without_testkits1 = np.append(x_without_testkits1, x2)\n    y_without_testkits1_mean = np.append(y_without_testkits1_mean, [np.sum(y2) / (y2.shape[0])])\n    y_without_testkits1_max = np.append(y_without_testkits1_max, [np.max(y2)])\n    y_without_testkits1_min = np.append(y_without_testkits1_min, [np.min(y2)])\n\n    # Increment the current epsilon step number\n    I_max_vs_epsilon_list = np.zeros(shape=(epsilon_steps, M))","metadata":{"papermill":{"duration":461.007876,"end_time":"2023-08-13T18:41:44.392820","exception":false,"start_time":"2023-08-13T18:34:03.384944","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {p}$\")\nplt.grid()\nplt.legend(loc = 'best')\n\n# plt.scatter(x_with_testkits1, y_with_testkits1, c='#5dbb63', label='With Testkits', s=1)\n# plt.scatter(x_without_testkits1, y_without_testkits1, c='#dc143c', label='Without Testkit', s=1)\n\nplt.fill_between(epsilon_list, y_with_testkits1_min, y_with_testkits1_max, color='#90ee90', label='With testkits (denoised)', alpha=0.5)\nplt.fill_between(epsilon_list, y_without_testkits1_min, y_without_testkits1_max, color='#ff8a8a', label='Without testkits (denoised)', alpha=0.5)\n\nplt.plot(epsilon_list, y_with_testkits1_mean, c='#013220', label='Mean of $I_{max}$ in nodes with testkits', linestyle = 'solid')\nplt.plot(epsilon_list, y_without_testkits1_mean, c='#750000', label='Mean of $I_{max}$ in nodes without testkits', linestyle = 'solid')\n\n# Plotting for reduced equations\nplt.plot(epsilon_list, x_with_testkitsR1, c='#4285F4', label='Mean of $I_{max}$ in nodes with testkits', linestyle = 'solid')\nplt.plot(epsilon_list, x_without_testkitsR1, c='#4285F4', label='Mean of $I_{max}$ in nodes without testkits', linestyle = 'solid')\n\n\nplt.xlabel(\"$\\log{\\epsilon}$\")\nplt.ylabel(\"$I_{max}$\")\n\nplt.xscale('log')\n\nplt.show()","metadata":{"papermill":{"duration":1.057632,"end_time":"2023-08-13T18:41:45.466301","exception":false,"start_time":"2023-08-13T18:41:44.408669","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X and Y with testkits\nx_with_testkits2 = np.array([])\ny_with_testkits2 = np.array([])\ny_with_testkits2_mean = np.array([])\ny_with_testkits2_max = np.array([])\ny_with_testkits2_min = np.array([])\n\n# X and Y without testkits\nx_without_testkits2 = np.array([])\ny_without_testkits2 = np.array([])\ny_without_testkits2_mean = np.array([])\ny_without_testkits2_max = np.array([])\ny_without_testkits2_min = np.array([])\n\n# Arrays for reduced equation solver\nx_with_testkitsR2 = np.array([])\nx_without_testkitsR2 = np.array([])\n    \nfor epsilon_value in epsilon_list:\n    # initial conditions\n    custom_E0 = np.random.randint(1, max_exposed, size=(M,1))\n#------------------Reduced Model-----------------------\n    E1,E2= custom_E0[0][0],custom_E0[l2][0]\n    # Initial conditions for given epsilon\n    X0= np.array([N-E1,E1,0,0,N-E2,E2,0,0,0,0,0])\n\n    X_flat = X0.ravel()\n\n    # Solving the initial value problem\n    solved_ivp = solve_ivp(ODE_for_reduced_eqns, (t0, tf), X_flat, args=(l2, M-l2, epsilon_value,  0.03, gamma, sigma, zeta, chi, a0, a1))\n\n    # Obtaining the Infection values for both communities\n    I_1 = solved_ivp.y[2]\n    I_2 = solved_ivp.y[6]\n\n    # Getting the I_max values from I_vals\n    I_max_1 = np.max(I_1)\n    I_max_2 = np.max(I_2)\n    \n    x_with_testkitsR2 = np.append(x_with_testkitsR2, I_max_1/N)\n    x_without_testkitsR2 = np.append(x_without_testkitsR2, I_max_2/N)\n#--------------------------------------------------------\n\n    # Solving the IVP using our solver function\n    solved_ivp = solver(adj_mat, adj_mat_normalised, degree_list, M, 0.03, ODE_multi_node_with_testkit, custom_E0, epsilon_value, M, l2)\n\n    # Obtaining the shape we need to realize the y values\n    reshape_vals = (6, M, solved_ivp.y.shape[1])\n    \n    # Getting the y value reshaped\n    jffy = solved_ivp.y.reshape(reshape_vals)[2]\n\n    # Obtaining the Infection values for each communities\n    I_vals = (solved_ivp.y.reshape(6, M, reshape_vals[2])[2]).reshape(M, reshape_vals[2])\n\n    # Getting the I_max values from I_vals\n    I_max = np.max(I_vals, axis=1).reshape(M, 1)\n    \n    # Colour list for testkit and testkit-free communities\n    color_list = [\"#F08080\", \"#80F080\", \"#8080F0\"]\n    \n    # x1, y1 for the \"with testkit nodes\"\n    x1 = np.full(M, epsilon_value)[:l2]\n    y1 = I_max.T[0][:l2] / N\n    marker_color_with_testkits = color_list[0]\n    \n    y_with_testkits2 = np.append(y_with_testkits2, y1)\n    x_with_testkits2 = np.append(x_with_testkits2, x1)\n    y_with_testkits2_mean = np.append(y_with_testkits2_mean, [np.sum(y1) / l2])\n    y_with_testkits2_max = np.append(y_with_testkits2_max, [np.max(y1)])\n    y_with_testkits2_min = np.append(y_with_testkits2_min, [np.min(y1)])\n    \n    # x2, y2 for the \"without testkit nodes\"\n    x2 = np.full(M, epsilon_value)[l2:-1]\n    y2 = I_max.T[0][l2:-1] / N\n    marker_color_without_testkits = color_list[1]\n    \n    y_without_testkits2 = np.append(y_without_testkits2, y2)\n    x_without_testkits2 = np.append(x_without_testkits2, x2)\n    y_without_testkits2_mean = np.append(y_without_testkits2_mean, [np.sum(y2) / (y2.shape[0])])\n    y_without_testkits2_max = np.append(y_without_testkits2_max, [np.max(y2)])\n    y_without_testkits2_min = np.append(y_without_testkits2_min, [np.min(y2)])\n    \n    # Increment the current epsilon step number\n    I_max_vs_epsilon_list = np.zeros(shape=(epsilon_steps, M))","metadata":{"papermill":{"duration":463.586271,"end_time":"2023-08-13T18:49:29.062139","exception":false,"start_time":"2023-08-13T18:41:45.475868","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nplt.title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {1. - p}$\")\nplt.grid()\nplt.legend(loc = 'best')\n\n# plt.scatter(x_with_testkits2, y_with_testkits2, c='#5dbb63', label='With Testkits', s=1)\n# plt.scatter(x_without_testkits2, y_without_testkits2, c='#dc143c', label='Without Testkit', s=1)\n\nplt.fill_between(epsilon_list, y_with_testkits2_min, y_with_testkits2_max, color='#90ee90', label='With testkits (denoised)', alpha=0.5)\nplt.fill_between(epsilon_list, y_without_testkits2_min, y_without_testkits2_max, color='#ff8a8a', label='Without testkits (denoised)', alpha=0.5)\n\nplt.plot(epsilon_list, y_with_testkits2_mean, c='#013220', label='Mean of $I_{max}$ in nodes with testkits', linestyle = 'solid')\nplt.plot(epsilon_list, y_without_testkits2_mean, c='#750000', label='Mean of $I_{max}$ in nodes without testkits', linestyle = 'solid')\n\n# Plotting for reduced equations\nplt.plot(epsilon_list, x_with_testkitsR2, c='#4285F4', label='Mean of $I_{max}$ in nodes with testkits', linestyle = 'solid')\nplt.plot(epsilon_list, x_without_testkitsR2, c='#4285F4', label='Mean of $I_{max}$ in nodes without testkits', linestyle = 'solid')\n\n\nplt.xlabel(\"$\\log{\\epsilon}$\")\nplt.ylabel(\"$I_{max}$\")\n\nplt.xscale('log')\n\nplt.show()","metadata":{"papermill":{"duration":0.853756,"end_time":"2023-08-13T18:49:29.938767","exception":false,"start_time":"2023-08-13T18:49:29.085011","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with plt.style.context('seaborn-paper'):\n    # Making the figure and axes\n    fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(38, 10))\n    \n    # Font sizes for everything\n    fs_label = 44\n    fs_ticks = 32\n    fs_title = 34\n    \n    ###############################################################\n    # Subplot 1\n    axs[0].fill_between(epsilon_list, y_with_testkits1_min, y_with_testkits1_max, color='#90ee90', alpha=0.5)\n    axs[0].fill_between(epsilon_list, y_without_testkits1_min, y_without_testkits1_max, color='#ff8a8a', alpha=0.5)\n\n    axs[0].plot(epsilon_list, y_with_testkits1_mean, c='#013220', label='Mean of $I_{max}$ in nodes with testkits', linestyle = '-.', linewidth=3)\n    axs[0].plot(epsilon_list, y_without_testkits1_mean, c='#750000', label='Mean of $I_{max}$ in nodes without testkits', linestyle = '-.', linewidth=3)\n    \n    # Plotting for reduced equations\n    axs[0].plot(epsilon_list, x_with_testkitsR1,'ob-', label='$I$ in testkit node in reduced eqns.')\n    axs[0].plot(epsilon_list, x_without_testkitsR1, 'ob-', label='$I$ in non-testkit node in reduced eqns.')\n\n    axs[0].set_xlabel(\"$\\log{\\epsilon}$\", fontsize=fs_label)\n    axs[0].set_ylabel(\"$I_{max}$\", fontsize=fs_label)\n    \n    axs[0].set_xscale('log')\n    \n    axs[0].set_title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {p}$\", fontsize=fs_title)\n    \n    ###############################################################\n    # Subplot 2\n    axs[1].fill_between(epsilon_list, y_with_testkits2_min, y_with_testkits2_max, color='#90ee90', alpha=0.5)\n    axs[1].fill_between(epsilon_list, y_without_testkits2_min, y_without_testkits2_max, color='#ff8a8a', alpha=0.5)\n\n    axs[1].plot(epsilon_list, y_with_testkits2_mean, c='#013220', label='Mean of $I_{max}$ in nodes with testkits', linestyle = '-.', linewidth=3)\n    axs[1].plot(epsilon_list, y_without_testkits2_mean, c='#750000', label='Mean of $I_{max}$ in nodes without testkits', linestyle = '-.', linewidth=3)\n    \n    # Plotting for reduced equations\n    axs[1].plot(epsilon_list, x_with_testkitsR2,'ob-', label='$I$ in testkit node in reduced eqns.')\n    axs[1].plot(epsilon_list, x_without_testkitsR2,'ob-', label='$I$ in non-testkit node in reduced eqns.')\n\n    axs[1].set_xlabel(\"$\\log{\\epsilon}$\", fontsize=fs_label)\n    axs[1].set_ylabel(\"$I_{max}$\", fontsize=fs_label)\n\n    axs[1].set_xscale('log')\n    \n    axs[1].set_title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {1. - p}$\", fontsize=fs_title)\n    \n    ###############################################################\n    \n    # Adding xlabels, legends, logscale(x), and grid\n    \n    for j in range(2):\n        axs[j].set_xlabel(\"$\\epsilon$\", fontsize = fs_label)\n#         axs[j].grid()\n#         axs[j].legend(loc = 'upper right', prop = {'size' : fs_legend})\n        axs[j].set_xscale('log')\n\n        axs[j].text(\n                    -0.1, \n                    1.1, \n                    string.ascii_uppercase[j], \n                    transform=axs[j].transAxes, \n                    size=35, \n                    weight='bold'\n                    )\n\n        axs[j].tick_params(direction= 'in', which='major', length=7,width=3)\n        axs[j].tick_params(direction= 'in', which='minor', length=5, width=2)\n\n        for axis in ['top','bottom','left','right']:\n            axs[j].spines[axis].set_linewidth(3)\n\n        x_ticks_labels = [r'$10^{-5}$', r'$10^{-3}$', r'$10^{-1}$', r'$10^{1}$']\n        x_ticks_vals = [10**(-5), 10**(-3), 10**(-1), 10**(1)]\n\n        axs[j].set_xticks([float(x_tick) for x_tick in x_ticks_vals],\n                         [str(x_tick) for x_tick in x_ticks_labels],\n                            fontsize=fs_ticks)\n\n        axs[j].set_xlim(epsilon_list[0], epsilon_list[-1])\n\n        y_ticks_imax = [0, 0.1, 0.2, 0.3]\n        axs[j].set_yticks([float(y_tick) for y_tick in y_ticks_imax],\n                         [str(round(y_tick, 2)) for y_tick in y_ticks_imax],\n                        fontsize=fs_ticks)\n            \n    # Adding ylabels\n\n    axs[0].set_ylabel(\"$I_{max}$\")\n\n    axs[0].set_ylim([-0.015,0.3+0.015])\n    axs[0].set_title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {p}$\", fontsize=fs_title)\n\n    axs[1].set_ylabel(\"$I_{max}$\")\n\n    axs[1].set_ylim([-0.015,0.3+0.015])\n    axs[1].set_title(f\"Clustering of communities with increasing $\\epsilon$ for $p = {float(1) - p}$\", fontsize=fs_title)\n    \n    labels_handles = {\n        label: handle for ax in fig.axes for handle, label in zip(*ax.get_legend_handles_labels())\n    }\n    \n    fs_legend= fs_title\n    \n    fig.legend(\n        labels_handles.values(),\n        labels_handles.keys(),\n        loc=\"lower center\",  # Change the location to \"lower center\" for bottom placement\n        ncol=2,  # Display the legend in two columns\n        bbox_to_anchor=(0.5, 1.05),  # Adjust the Y value to move the legend to the bottom\n        bbox_transform=plt.gcf().transFigure,\n        fontsize=fs_legend,  # Set the font size for the legend\n    )\n    fig.savefig('complete_red_model.pdf', dpi=1200, bbox_inches='tight')","metadata":{"papermill":{"duration":3.24709,"end_time":"2023-08-13T18:49:33.196196","exception":false,"start_time":"2023-08-13T18:49:29.949106","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.014746,"end_time":"2023-08-13T18:49:33.225747","exception":false,"start_time":"2023-08-13T18:49:33.211001","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}